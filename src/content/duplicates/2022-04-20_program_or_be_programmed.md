---
title: Program or Be Programmed
subtitle: Ten years ago, I realized media literacy meant something different
date: 2022-04-20
blurb: That’s why the original commands we give our computers are so important. Whatever values we embed will be the values they achieve.
notes: Source: [https://rushkoff.medium.com/program-or-be-programmed-633fb8f045f3](https://rushkoff.medium.com/program-or-be-programmed-633fb8f045f3 https://rushkoff.medium.com/program-or-be-programmed-633fb8f045f3)
source: 
publication: medium
---

As media theorist [John Culkin first observed](http://www.medialit.org/reading-room/john-culkin-sj-man-who-invented-media-literacy-1928-1993), we shape our technologies at the moment of their conception, but from that point forward they shape us. We humans designed the telephone, but from then on the telephone influenced how we communicated, conducted business, and conceived of the world. We also invented the automobile, but then rebuilt our cities around automotive travel and our geopolitics around fossil fuels.

This axiom holds true for technologies from the pencil to the birth control pill. But computers, algorithms, and artificial intelligences add another twist: after we launch them, they not only shape us but they also begin to shape _themselves_. We give them an initial goal, then give them all the data they need to figure out how to accomplish it. From that point forward, we humans no longer fully understand how an AI may be processing information or modifying its tactics. The machine isn’t conscious enough to tell us. It’s just trying everything, and hanging onto what works.

Researchers have found, for example, that the algorithms running social media platforms tend to show people pictures of their ex-lovers having fun. No, users don’t want to see such images. But, through trial and error, the algorithms have discovered that showing us pictures of our exes having fun increases our engagement. We are drawn to click on those pictures and see what our exes are up to, and we’re more likely to do it if we’re jealous that they’ve found a new partner. The algorithms don’t know why this works, and they don’t care. They’re only trying to maximize whichever metric we’ve instructed them to pursue.

That’s why the original commands we give our computers are so important. Whatever values we embed — such as efficiency, growth, security or compliance, for example — will be the values they achieve. And they’ll do so by whatever means happen to work. Machine intelligences will be using techniques that no one — not even they — understand. And they will be honing them to generate better results, and then using those results to iterate further. To a hammer, everything is a nail. To a computer, everything is a computational challenge.

We must not accept any technology as the default solution for our problems. When we do, we end up trying to optimize ourselves for our machines, instead of optimizing our machines for us. Whenever people or institutions fail, we assume they are simply lacking the appropriate algorithms or upgrades.

By starting with the assumption that our problems are fixable by technology, we end up emphasizing very particular strategies. We improve the metrics that a given technology can improve, but often ignore or leave behind the sorts of problems that the technology can’t address. We move out of balance, because our money and effort only go toward the things we can solve and the people who can pay for those solutions. That is why today, we’ve got a greater part of humanity working on making our social media feeds more persuasive than we have on making clean water more accessible. We build our world around what our technologies can do.

As I tried to demonstrate in my book _Program or Be Programmed,_ which is now celebrating its tenth anniversary, most technologies start out as mere tools. At first they exist to serve our needs, and don’t directly contradict our worldview or our way of life. If anything, we use them to express our own, existing values. We built airplanes so humans could experience flight and travel great distances. We developed radio to extend our voices across space. Their primary impact on our world is to execute their original purpose.

However, as technologies become more a part of our world, we begin making more accommodations to their functioning. We learn to cross the street carefully so as not to be hit by auto- mobiles, we clear-cut a forest to make way for electric cables, or we dedicate a room devoted to conversation and family — the living room — to the television. The technology forces negotiations and compromises.

Without human intervention, technology becomes an accepted premise of our value system: the starting point from which everything else must be inferred. In a world of text, illiteracy is the same as stupidity, and the written law may as well be the word of God. In a world defined by computers, speed and efficiency become the primary values. Refusing a technological upgrade may as well be a rejection of the social norm, or a desire to remain sick, weak, and unrepentantly human.

To most of the developers and investors of Silicon Valley, however, humans are not to be emulated or celebrated, but transcended or — at the very least — reengineered. These technologists are so dominated by the values of the digital revolution that they see anything or anyone with different priorities as an impediment. This is a distinctly antihuman position, and it’s driving the development philosophy of the most capitalized companies on the planet.

Human beings are not the problem. We are the solution. Only by taking command of our technologies can we promote a future in which we will thrive together.
